{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everyone involved (and the audience) should se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Williams family live on a ranch located in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie surprised me in a good way. From th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Forget Neo and Bourne and all those half-baked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I figured that any horror film with Orson Well...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Everyone involved (and the audience) should se...      0\n",
       "1  The Williams family live on a ranch located in...      1\n",
       "2  This movie surprised me in a good way. From th...      1\n",
       "3  Forget Neo and Bourne and all those half-baked...      1\n",
       "4  I figured that any horror film with Orson Well...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_pth = \"./data/imdb\"\n",
    "train = pd.read_csv(f\"{data_pth}/train.csv\")\n",
    "val = pd.read_csv(f\"{data_pth}/val.csv\")\n",
    "test = pd.read_csv(f\"{data_pth}/test.csv\")\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import clean_text\n",
    "\n",
    "if \"text_cleaned\" not in train.columns:\n",
    "    train[\"text_cleaned\"] = train[\"text\"].map(lambda t: clean_text(t))\n",
    "    train.to_csv(f\"{data_pth}/train_cleaned.csv\", index=False)\n",
    "else:\n",
    "    print(\"Loaded Train Cleaned Dataset\")\n",
    "\n",
    "if \"text_cleaned\" not in test.columns:\n",
    "    test[\"text_cleaned\"] = test[\"text\"].map(lambda t: clean_text(t))\n",
    "    test.to_csv(f\"{data_pth}/test_cleaned.csv\", index=False)\n",
    "else:\n",
    "    print(\"Loaded Test Cleaned Dataset\")\n",
    "\n",
    "if \"text_cleaned\" not in val.columns:\n",
    "    val[\"text_cleaned\"] = val[\"text\"].map(lambda t: clean_text(t))\n",
    "    val.to_csv(f\"{data_pth}/val_cleaned.csv\", index=False)\n",
    "else:\n",
    "    print(\"Loaded Val Cleaned Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw:  Everyone involved (and the audience) should seek out \"The Candidate\" to see how good this movie could have been. What happened the South American story? What were Julie Christie and Kate Capshaw thinking to allow their roles to be cardboard cut-outs. Up to now I have liked every Gene Hackman performance and/or movie. He was either disinterested (which I can hardly believe) or dreadfully miscast. I have also liked and defended Richard Gere (and been vilified for it). But here he had no \"power\". He was never intimidating and only occasionally persuasive. All in all I was very disappointed. I really expected much more from this director and cast. If you can't find \"The Candidate\" watch \"Wag the dog\" again or even \"Bulworth\".\n",
      "Cleaned:  everyone involved and the audience should seek out the candidate to see how good this movie could have been what happened the south american story ? what were julie christie and kate capshaw thinking to allow their roles to be cardboard cutouts up to now i have liked every gene hackman performance andor movie he was either disinterested which i can hardly believe or dreadfully miscast i have also liked and defended richard gere and been vilified for it but here he had no power he was never intimidating and only occasionally persuasive all in all i was very disappointed i really expected much more from this director and cast if you cant find the candidate watch wag the dog again or even bulworth\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw: \", train.iloc[0,0])\n",
    "print(\"Cleaned: \", train.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [text for text in train[\"text_cleaned\"]]\n",
    "test_texts = [text for text in test[\"text_cleaned\"]]\n",
    "val_texts = [text for text in val[\"text_cleaned\"]]\n",
    "\n",
    "train_labels = [senti for senti in train[\"label\"]]\n",
    "test_labels = [senti for senti in test[\"label\"]]\n",
    "val_labels = [senti for senti in val[\"label\"]]\n",
    "\n",
    "splitted_texts, splitted_labels = {\"train\": train_texts, \"test\": test_texts, \"val\": val_texts},  {\"train\": train_labels, \"test\": test_labels, \"val\": val_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-crafting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from features import craft_features, vectorize_labels, FEAT_ARG\n",
    "\n",
    "NGRAM_RANGE = (1,3)\n",
    "MAX_TFIDF_FEATS = 2000\n",
    "MIN_DF = 3\n",
    "MAX_DF = 0.7\n",
    "\n",
    "args = FEAT_ARG(NGRAM_RANGE, MIN_DF, MAX_DF, MAX_TFIDF_FEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ngram tfidf over training set...\n",
      "Fitted! Saving into ./models\n",
      "Features:  Train (20000, 2000) , Val (5000, 2000) , Test (25000, 2000)\n"
     ]
    }
   ],
   "source": [
    "FEATURESET = \"tfidf\"\n",
    "X_train, X_val, X_test = craft_features(featset=FEATURESET, text_splits=splitted_texts, feat_args=args)\n",
    "y_train, y_val, y_test = vectorize_labels(splitted_labels)\n",
    "\n",
    "print(\"Features:  Train {} , Val {} , Test {}\".format(X_train.shape, X_val.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Modeling (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: l1 0.1\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91     10000\n",
      "           1       0.90      0.91      0.91     10000\n",
      "\n",
      "    accuracy                           0.91     20000\n",
      "   macro avg       0.91      0.91      0.91     20000\n",
      "weighted avg       0.91      0.91      0.91     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      2500\n",
      "           1       0.84      0.85      0.85      2500\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.85      0.85      0.85      5000\n",
      "weighted avg       0.85      0.85      0.85      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86     12500\n",
      "           1       0.86      0.87      0.86     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.86      0.86      0.86     25000\n",
      "weighted avg       0.86      0.86      0.86     25000\n",
      "\n",
      "Model: l1 1.0\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     10000\n",
      "           1       0.88      0.90      0.89     10000\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.89      0.89      0.89     20000\n",
      "weighted avg       0.89      0.89      0.89     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      2500\n",
      "           1       0.85      0.88      0.87      2500\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     12500\n",
      "           1       0.86      0.88      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "Model: l1 5.0\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84     10000\n",
      "           1       0.83      0.87      0.85     10000\n",
      "\n",
      "    accuracy                           0.85     20000\n",
      "   macro avg       0.85      0.85      0.85     20000\n",
      "weighted avg       0.85      0.85      0.85     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      2500\n",
      "           1       0.83      0.86      0.84      2500\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.84      0.84      0.84      5000\n",
      "weighted avg       0.84      0.84      0.84      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.84     12500\n",
      "           1       0.82      0.87      0.85     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "Model: l2 0.1\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90     10000\n",
      "           1       0.90      0.91      0.90     10000\n",
      "\n",
      "    accuracy                           0.90     20000\n",
      "   macro avg       0.90      0.90      0.90     20000\n",
      "weighted avg       0.90      0.90      0.90     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85      2500\n",
      "           1       0.85      0.86      0.85      2500\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.85      0.85      0.85      5000\n",
      "weighted avg       0.85      0.85      0.85      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86     12500\n",
      "           1       0.86      0.87      0.87     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.87      0.86      0.86     25000\n",
      "weighted avg       0.87      0.86      0.86     25000\n",
      "\n",
      "Model: l2 1.0\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     10000\n",
      "           1       0.88      0.90      0.89     10000\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.89      0.89      0.89     20000\n",
      "weighted avg       0.89      0.89      0.89     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      2500\n",
      "           1       0.86      0.87      0.87      2500\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     12500\n",
      "           1       0.86      0.88      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "Model: l2 5.0\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     10000\n",
      "           1       0.86      0.88      0.87     10000\n",
      "\n",
      "    accuracy                           0.87     20000\n",
      "   macro avg       0.87      0.87      0.87     20000\n",
      "weighted avg       0.87      0.87      0.87     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      2500\n",
      "           1       0.85      0.87      0.86      2500\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.85      0.85      0.85      5000\n",
      "weighted avg       0.85      0.85      0.85      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86     12500\n",
      "           1       0.85      0.87      0.86     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.86      0.86      0.86     25000\n",
      "weighted avg       0.86      0.86      0.86     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in [\"l1\", \"l2\"]:\n",
    "    for lambda_ in [0.1, 1.0, 5.0]:\n",
    "        print(f\"Model: {p} {lambda_}\")\n",
    "        lr = LogisticRegression(C=1/lambda_, penalty=p, solver=\"liblinear\", max_iter=5000)\n",
    "        lr.fit(X_train, y_train)\n",
    "        train_pred = lr.predict(X_train)\n",
    "        val_pred = lr.predict(X_val)\n",
    "        test_pred = lr.predict(X_test)\n",
    "        print(\"Trainset\")\n",
    "        print(classification_report(y_train, train_pred))\n",
    "        print(\"Valset\")\n",
    "        print(classification_report(y_val, val_pred))\n",
    "        print(\"Testset\")\n",
    "        print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# clf = GradientBoostingClassifier(n_estimators=100, \n",
    "#                                  learning_rate=1.,\n",
    "#                                  max_depth=3, \n",
    "#                                  random_state=42,\n",
    "#                                  verbose=1)\n",
    "# clf.fit(X_train, y_train)\n",
    "# train_pred = clf.predict(X_train)\n",
    "# val_pred = clf.predict(X_val)\n",
    "# test_pred = clf.predict(X_test)\n",
    "\n",
    "# print(\"Trainset\")\n",
    "# print(classification_report(y_train, train_pred))\n",
    "# print(\"Valset\")\n",
    "# print(classification_report(y_val, val_pred))\n",
    "# print(\"Testset\")\n",
    "# print(classification_report(y_test, test_pred))\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "# clf = xgb.XGBClassifier(n_estimators=1000,\n",
    "#                         learning_rate=0.1,\n",
    "#                         max_depth=3,\n",
    "#                         random_state=42,\n",
    "#                         verbosity=1,\n",
    "#                         use_label_encoder=False,\n",
    "#                         eval_metric='logloss')\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "# train_pred = clf.predict(X_train)\n",
    "# val_pred = clf.predict(X_val)\n",
    "# test_pred = clf.predict(X_test)\n",
    "\n",
    "# print(\"Trainset\")\n",
    "# print(classification_report(y_train, train_pred))\n",
    "# print(\"Valset\")\n",
    "# print(classification_report(y_val, val_pred))\n",
    "# print(\"Testset\")\n",
    "# print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM_RANGE = (1,3)\n",
    "MIN_DF = 3\n",
    "MAX_DF = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set: tfidf N=200\n",
      "Load a pre-trained vectorizer: tfidf_vectorizer_ngram(1, 3)_max_200_dfminmax_3_0.7.pickle\n",
      "Features:  Train (20000, 200) , Val (5000, 200) , Test (25000, 200)\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77     10000\n",
      "           1       0.76      0.78      0.77     10000\n",
      "\n",
      "    accuracy                           0.77     20000\n",
      "   macro avg       0.77      0.77      0.77     20000\n",
      "weighted avg       0.77      0.77      0.77     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      2500\n",
      "           1       0.75      0.76      0.76      2500\n",
      "\n",
      "    accuracy                           0.76      5000\n",
      "   macro avg       0.76      0.76      0.76      5000\n",
      "weighted avg       0.76      0.76      0.76      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76     12500\n",
      "           1       0.76      0.76      0.76     12500\n",
      "\n",
      "    accuracy                           0.76     25000\n",
      "   macro avg       0.76      0.76      0.76     25000\n",
      "weighted avg       0.76      0.76      0.76     25000\n",
      "\n",
      "Feature set: tfidf N=2000\n",
      "Load a pre-trained vectorizer: tfidf_vectorizer_ngram(1, 3)_max_2000_dfminmax_3_0.7.pickle\n",
      "Features:  Train (20000, 2000) , Val (5000, 2000) , Test (25000, 2000)\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     10000\n",
      "           1       0.88      0.90      0.89     10000\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.89      0.89      0.89     20000\n",
      "weighted avg       0.89      0.89      0.89     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      2500\n",
      "           1       0.86      0.87      0.87      2500\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     12500\n",
      "           1       0.86      0.88      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "Feature set: tfidf N=5000\n",
      "Load a pre-trained vectorizer: tfidf_vectorizer_ngram(1, 3)_max_5000_dfminmax_3_0.7.pickle\n",
      "Features:  Train (20000, 5000) , Val (5000, 5000) , Test (25000, 5000)\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91     10000\n",
      "           1       0.91      0.92      0.92     10000\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.92      0.92      0.92     20000\n",
      "weighted avg       0.92      0.92      0.92     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      2500\n",
      "           1       0.87      0.89      0.88      2500\n",
      "\n",
      "    accuracy                           0.88      5000\n",
      "   macro avg       0.88      0.88      0.88      5000\n",
      "weighted avg       0.88      0.88      0.88      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88     12500\n",
      "           1       0.88      0.89      0.89     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n",
      "Feature set: tfidf+lexicon N=200\n",
      "Load a pre-trained vectorizer: tfidf_vectorizer_ngram(1, 3)_max_200_dfminmax_3_0.7.pickle\n",
      "Load a pre-trained vectorizer: count_vectorizer_ngram(1, 3)_max_None_dfminmax_3_0.7.pickle\n",
      "Retrieved Sentiment Lexicon with length 6786\n",
      "Found 4372/6786 lexemes in training vocabulary\n",
      "Found 4372/6786 lexemes in training vocabulary\n",
      "Found 4372/6786 lexemes in training vocabulary\n",
      "Features:  Train (20000, 6986) , Val (5000, 6986) , Test (25000, 6986)\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92     10000\n",
      "           1       0.92      0.93      0.92     10000\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.92      0.92      0.92     20000\n",
      "weighted avg       0.92      0.92      0.92     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      2500\n",
      "           1       0.85      0.86      0.85      2500\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.85      0.85      0.85      5000\n",
      "weighted avg       0.85      0.85      0.85      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85     12500\n",
      "           1       0.85      0.86      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n",
      "Feature set: tfidf+lexicon N=2000\n",
      "Load a pre-trained vectorizer: tfidf_vectorizer_ngram(1, 3)_max_2000_dfminmax_3_0.7.pickle\n",
      "Load a pre-trained vectorizer: count_vectorizer_ngram(1, 3)_max_None_dfminmax_3_0.7.pickle\n",
      "Retrieved Sentiment Lexicon with length 6786\n",
      "Found 4372/6786 lexemes in training vocabulary\n",
      "Found 4372/6786 lexemes in training vocabulary\n",
      "Found 4372/6786 lexemes in training vocabulary\n",
      "Features:  Train (20000, 8786) , Val (5000, 8786) , Test (25000, 8786)\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     10000\n",
      "           1       0.94      0.95      0.94     10000\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.94      0.94      0.94     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      2500\n",
      "           1       0.86      0.88      0.87      2500\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87     12500\n",
      "           1       0.86      0.87      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "Feature set: tfidf+lexicon N=5000\n",
      "Load a pre-trained vectorizer: tfidf_vectorizer_ngram(1, 3)_max_5000_dfminmax_3_0.7.pickle\n",
      "Load a pre-trained vectorizer: count_vectorizer_ngram(1, 3)_max_None_dfminmax_3_0.7.pickle\n",
      "Retrieved Sentiment Lexicon with length 6786\n",
      "Found 4372/6786 lexemes in training vocabulary\n",
      "Found 4372/6786 lexemes in training vocabulary\n",
      "Found 4372/6786 lexemes in training vocabulary\n",
      "Features:  Train (20000, 11786) , Val (5000, 11786) , Test (25000, 11786)\n",
      "Trainset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     10000\n",
      "           1       0.95      0.95      0.95     10000\n",
      "\n",
      "    accuracy                           0.95     20000\n",
      "   macro avg       0.95      0.95      0.95     20000\n",
      "weighted avg       0.95      0.95      0.95     20000\n",
      "\n",
      "Valset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      2500\n",
      "           1       0.87      0.88      0.87      2500\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "Testset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     12500\n",
      "           1       0.87      0.88      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for FEATURESET in [\"tfidf\", \"tfidf+lexicon\"]:\n",
    "    for MAX_TFIDF_FEATS in [200, 2000, 5000]:\n",
    "\n",
    "        print(f\"Feature set: {FEATURESET} N={MAX_TFIDF_FEATS}\")\n",
    "\n",
    "        args = FEAT_ARG(NGRAM_RANGE, MIN_DF, MAX_DF, MAX_TFIDF_FEATS)\n",
    "        X_train, X_val, X_test = craft_features(featset=FEATURESET, text_splits=splitted_texts, feat_args=args)\n",
    "        y_train, y_val, y_test = vectorize_labels(splitted_labels)\n",
    "        print(\"Features:  Train {} , Val {} , Test {}\".format(X_train.shape, X_val.shape, X_test.shape))\n",
    "        \n",
    "        \n",
    "        lr = LogisticRegression(C=1., penalty=\"l2\", solver=\"liblinear\", max_iter=5000)\n",
    "        lr.fit(X_train, y_train)\n",
    "        train_pred = lr.predict(X_train)\n",
    "        val_pred = lr.predict(X_val)\n",
    "        test_pred = lr.predict(X_test)\n",
    "\n",
    "        print(\"Trainset\")\n",
    "        print(classification_report(y_train, train_pred))\n",
    "        print(\"Valset\")\n",
    "        print(classification_report(y_val, val_pred))\n",
    "        print(\"Testset\")\n",
    "        print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
